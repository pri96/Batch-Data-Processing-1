{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a834ed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.sql import SparkSession, HiveContext\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#sc1 = sp.SparkContext.getOrCreate()\n",
    "sc = SparkContext(\"local\", \"First-app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e8d2604e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkSession and sqlContext\n",
    "spark = SparkSession.builder.master(sc.master) \\\n",
    "                    .appName(sc.appName) \\\n",
    "                    .enableHiveSupport() \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8e01afa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function for text formatting\n",
    "#specialCharacters = \"!@#$%^&'*()+?_=<>1234567890/\"\n",
    "special_char_remove = [\"!\",\"@\",\"#\",\"$\",\"%\",\"^\",\"&\",\"'\",\"*\",\"“\",\"”\",\"—\",\"’\",\"‘\",\"·\",\"´\",\"(\",\")\",\"/\",\"+\",\"ð\",\"°\",\"º\"\n",
    "                       ,\"?\",\"•\",\"~\",\"£\",\"_\",\"|\",\"=\",\"<\",\">\",\"æ\",\"Æ\",\"œ\",\"½\",\"―\",\"…\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"0\"\n",
    "                       ,\"è\",\"à\",\"ê\",\"â\",\"ù\",\"ô\",\"ö\",\"Ö\",\"é\",\"î\",\"û\",\"ì\",\"ü\",\"Ü\",\"ò\",\"á\",\"ñ\",\"ç\",\"ó\",\"ä\",\"ë\",\"ï\",\"í\",\"ú\",\"ý\"];\n",
    "\n",
    "#I thought you would have gone home long ago. Dinner ’ll be \n",
    "def FilterAndFormatText(inputText):\n",
    "    arrayWords = []\n",
    "    returnText = re.sub(\"[_.;:\\[\\]\\\"?!,(){}-]\", \" \", inputText)\n",
    "    arrayWords = GetFilteredText(returnText.split(' '))\n",
    "    #arrayWords = FilterNumberTexts(arrayWords)\n",
    "    #arrayWords = FilterSpecialCharacters(arrayWords)\n",
    "    finalTextFiltered = \" \".join(arrayWords)\n",
    "    #return re.sub('[^a-zA-Z ]+', '', finalTextFiltered).lower()\n",
    "    return re.sub('[^a-zA-Z ]+', '', finalTextFiltered).lower()\n",
    "\n",
    "def GetFilteredText(arrInput):\n",
    "    filteredArray = []\n",
    "    for i in range(len(arrInput)):\n",
    "        print(arrInput[i].encode('utf-8'))\n",
    "        if any(s in arrInput[i].lower() for s in special_char_remove):\n",
    "            print(arrInput[i])\n",
    "        else:\n",
    "            filteredArray.append(arrInput[i])\n",
    "           \n",
    "    return filteredArray\n",
    "\n",
    "#print(FilterAndFormatText(\"Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.\"\n",
    "#+\" Kubernetes KuberneteS Kuber5netes kubernetes Kubernetes7 KuberneTes \"\n",
    "#+\" SystEM Sys System. system, sYstem> >>> 8765 Kubernetes@Kubernetes.com applications. applications (applications,applications)++({applications})\"\n",
    "#+\" {PPP} {nnb}\"\n",
    "#+\" gg hh jj k mmm iii yyy vv ccc ff rr eee ss dd rrr tttt yy tt tt ttt uu iii www qqq aa ww33 ee ddd cc vvb nn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c0fc7cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to accept the file and generate the output the file according to input\n",
    "def ParseFileData(fileName):\n",
    "    filePath = \"D:\\Project\\Input Output\\\\\"+fileName+\".txt\"\n",
    "    textFile = sc.textFile(filePath)\n",
    "\n",
    "    # WordCount started\n",
    "    textFlatWord = textFile.flatMap(lambda line: FilterAndFormatText(line).split(' ')) \\\n",
    "                            .map(lambda word: (word, 1)) \\\n",
    "                           .reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "    # CharCount started\n",
    "    textFlatChar = textFile.flatMap(lambda each: FilterAndFormatText(each)) \\\n",
    "                            .map(lambda char: char) \\\n",
    "                            .map(lambda c: (c, 1)) \\\n",
    "                            .reduceByKey(lambda v1, v2: v1 + v2)\n",
    "\n",
    "    # Convert flat data int DataFrame\n",
    "    wordDF = spark.createDataFrame(textFlatWord,['Word', 'Frequency'])\n",
    "\n",
    "    # Convert flat data int DataFrame\n",
    "    charDF = spark.createDataFrame(textFlatChar,['Letter', 'Frequency'])\n",
    "    \n",
    "    #word Calculation\n",
    "    wordDF = wordDF[wordDF[\"Word\"] != '']\n",
    "    wordDF = wordDF[wordDF[\"Word\"] != ' ']\n",
    "    windowSpec = Window.orderBy(f.desc(\"Frequency\"), f.asc(\"Word\"))\n",
    "    wordDF = wordDF.withColumn(\"Rank\",f.row_number().over(windowSpec))\n",
    "    \n",
    "    totalRank = wordDF.select(\"Rank\").rdd.max()[0]\n",
    "    \n",
    "    T1 = math.ceil((5 * totalRank)/100)\n",
    "    T2 = math.floor((47.5 * totalRank)/100)\n",
    "    T3 = math.ceil((52.5 * totalRank)/100)\n",
    "    T4 = math.floor((95 * totalRank)/100)\n",
    "    \n",
    "    dfPopular = wordDF[wordDF[\"Rank\"].between(1, T1)]\n",
    "    dfCommon = wordDF[wordDF[\"Rank\"].between(T2, T3)]\n",
    "    dfRare = wordDF[wordDF[\"Rank\"] >= T4]\n",
    "    \n",
    "    charDF = charDF[charDF[\"Letter\"] != ' ']\n",
    "    charDF = charDF[charDF[\"Letter\"] != '']\n",
    "\n",
    "    charWindowSpec = Window.orderBy(f.desc(\"Frequency\"), f.asc(\"Letter\"))\n",
    "    charDF = charDF.withColumn(\"Rank\",f.row_number().over(charWindowSpec))\n",
    "    \n",
    "    charTotalRank = charDF.select(\"Rank\").rdd.max()[0]\n",
    "    \n",
    "    T1Char = math.ceil((5 * charTotalRank)/100)\n",
    "    T2Char = math.floor((47.5 * charTotalRank)/100)\n",
    "    T3Char = math.ceil((52.5 * charTotalRank)/100)\n",
    "    T4Char = math.floor((95 * charTotalRank)/100)\n",
    "    \n",
    "    dfPopularChar = charDF[charDF[\"Rank\"].between(1, T1Char)]\n",
    "    dfCommonChar = charDF[charDF[\"Rank\"].between(T2Char, T3Char)]\n",
    "    dfRareChar = charDF[charDF[\"Rank\"] >= T4Char]\n",
    "    \n",
    "    file1 = open(\"output-\"+fileName + \".txt\",\"w\")\n",
    "\n",
    "    file1.write('-----------------------------------------------------------------------------------------\\n')\n",
    "    file1.write('Output for  ' + fileName + '\\n')\n",
    "    file1.write('-----------------------------------------------------------------------------------------\\n')\n",
    "    \n",
    "    file1.write('total number of distinct words= ' + str(totalRank) + '\\n')\n",
    "    file1.write('popular_threshold_word= ' + str(T1) + '\\n')\n",
    "    file1.write('common_threshold_l_word= ' + str(T2) + '\\n')\n",
    "    file1.write('common_threshold_u_word= ' + str(T3) + '\\n')\n",
    "    file1.write('rare_threshold_word= ' + str(T4) + '\\n')\n",
    "    \n",
    "    def WriteToFileDFWord(df, writeType):\n",
    "        file1.write('\\n' + writeType + '\\n')\n",
    "        file1.write('+------+---------+------+\\n')\n",
    "        file1.write('|Rank|Frequency|Word  |\\n')\n",
    "        file1.write('+------+---------+------+\\n')\n",
    "\n",
    "        pandasDF = df.toPandas()\n",
    "        for index, row in pandasDF.iterrows():\n",
    "            #file1.write('| ' + str(row['Letter']) + '    | ' + str(row['Frequency']) + '       | ' + str(row['Rank']) + '   |\\n')\n",
    "            file1.write(str(row['Rank']) +'    '+ str(row['Frequency']) +'    '+ str(row['Word']) + '\\n')\n",
    "\n",
    "        file1.write('+------+---------+------+\\n')\n",
    "    \n",
    "    WriteToFileDFWord(dfPopular, 'Popular Words')\n",
    "    WriteToFileDFWord(dfCommon, 'Common Word')\n",
    "    WriteToFileDFWord(dfRare, 'Rare Word')\n",
    "    \n",
    "    \n",
    "    file1.write('\\n-----------------------------------------------------------------------------------------\\n')\n",
    "    file1.write('total number of distinct letters= ' + str(charTotalRank) + '\\n')\n",
    "    file1.write('popular_threshold_letter= ' + str(T1Char) + '\\n')\n",
    "    file1.write('common_threshold_l_letter= ' + str(T2Char) + '\\n')\n",
    "    file1.write('common_threshold_u_letter= ' + str(T3Char) + '\\n')\n",
    "    file1.write('rare_threshold_letter= ' + str(T4Char) + '\\n')\n",
    "    file1.write('-----------------------------------------------------------------------------------------\\n')\n",
    "\n",
    "    def WriteToFileDF(df, writeType):\n",
    "        file1.write('\\n' + writeType + '\\n')\n",
    "        file1.write('+------+---------+------+\\n')\n",
    "        file1.write('|Rank|Frequency|Letter  |\\n')\n",
    "        file1.write('+------+---------+------+\\n')\n",
    "\n",
    "        pandasDF = df.toPandas()\n",
    "        for index, row in pandasDF.iterrows():\n",
    "            #file1.write('| ' + str(row['Letter']) + '    | ' + str(row['Frequency']) + '       | ' + str(row['Rank']) + '   |\\n')\n",
    "            file1.write(str(row['Rank']) +'    '+ str(row['Frequency']) +'    '+ str(row['Letter']) + '\\n')\n",
    "\n",
    "        file1.write('+------+---------+------+\\n')\n",
    "\n",
    "    WriteToFileDF(dfPopularChar, 'Popular Letters')\n",
    "    WriteToFileDF(dfCommonChar, 'Common Letters')\n",
    "    WriteToFileDF(dfRareChar, 'Rare Letters')\n",
    "    file1.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e753c0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ParseFileData('sample-a')\n",
    "ParseFileData('sample-b')\n",
    "ParseFileData('sample-c')\n",
    "ParseFileData('sample-d')\n",
    "ParseFileData('sample-e')\n",
    "ParseFileData('sample-f')\n",
    "ParseFileData('sample-g')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "52754e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
